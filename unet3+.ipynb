{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11604,"status":"ok","timestamp":1713437349797,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"Qo0AfZoRbhbP"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split, Dataset\n","import numpy as np\n","from dataloader import PASTIS_Dataset\n","from collate import pad_collate\n","import torch.nn.functional as F\n","from tqdm.auto import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import datasets\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from torch.cuda.amp import autocast, GradScaler\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap, BoundaryNorm\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"markdown","metadata":{"id":"KFv0xdWdbhbS"},"source":["Порядок комментариев к коду: китайский / русский / английский."]},{"cell_type":"markdown","metadata":{"id":"vS5OxHuLbhbW"},"source":["数据集加载 / Загрузка набора данных / loading dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1713437349798,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"cqcG1vjIbhbW"},"outputs":[],"source":["class DynamicTimePointDataset(Dataset):\n","    def __init__(self, dataset, indices):\n","        self.dataset = dataset\n","        self.indices = indices\n","        self.index_mapping = self._create_index_mapping()\n","\n","    def _create_index_mapping(self):\n","        mapping = []\n","        for idx in self.indices:\n","            (data, dates), target = self.dataset[idx]\n","            s2_data = data['S2']\n","            num_time_points = s2_data.shape[0]\n","            for time_point in range(num_time_points):\n","                mapping.append((idx, time_point))\n","        return mapping\n","\n","    def __len__(self):\n","        return len(self.index_mapping)\n","\n","    def __getitem__(self, idx):\n","        patch_idx, time_point_idx = self.index_mapping[idx]\n","        (data, dates), target = self.dataset[patch_idx]\n","        s2_data = data['S2']\n","        time_point_data = s2_data[time_point_idx].unsqueeze(0) \n","        return time_point_data, target\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"elapsed":159109,"status":"error","timestamp":1713438240339,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"6CRcAyUrbhbX","outputId":"0f3f454b-4345-45ea-cf01-40768ff93f40"},"outputs":[],"source":["# 获取并处理数据集 / Получение и обработка набора данных / Getting and processing the dataset\n","path_to_dataset = 'E:/Research/Newdata/PASTIS'\n","dataset = PASTIS_Dataset(path_to_dataset, norm=True, target='semantic') # 使用语义分割标签 / Использование меток семантической сегментации / Using semantic segmentation labels\n","\n","subset_indices = torch.randperm(len(dataset))[:1500].tolist()\n","dynamic_dataset = DynamicTimePointDataset(dataset, subset_indices)\n","total_samples = len(dynamic_dataset)\n","print(f\"Total number of data samples: {total_samples}\")\n","\n","# 划分训练集和验证集 / Разделение на обучающий и проверочный наборы / Splitting into training and validation sets\n","train_size = int(0.8 * len(dynamic_dataset))\n","valid_size = len(dynamic_dataset) - train_size\n","train_dataset, valid_dataset = random_split(dynamic_dataset, [train_size, valid_size])\n","\n","# 创建 DataLoader / Создание DataLoader / Creating DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=pad_collate, shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=16, collate_fn=pad_collate, pin_memory=True)\n","\n","# 类别数 / Количество классов / Number of classes\n","num_classes = 20"]},{"cell_type":"markdown","metadata":{"id":"m_shAYWabhbT"},"source":["UNET 3+/ Модель UNET 3+ / UNET 3+ model"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1713438240340,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"ZK4na3ohbhbT"},"outputs":[],"source":["# Double Convolution / двойная свертка\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","# Encoder / кодер\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","# Decoder / декодер\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","\n","        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2 if bilinear else None)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1713438240340,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"9zw0G7NxbhbU"},"outputs":[],"source":["class UNet3Plus(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=True):\n","        super(UNet3Plus, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        self.down4 = Down(512, 512)\n","\n","        self.up1 = Up(768, 256, bilinear)\n","        self.up2 = Up(512, 128, bilinear)\n","        self.up3 = Up(320, 64, bilinear)\n","        self.up4 = Up(192, 64, bilinear)\n","\n","        self.outc = OutConv(64, n_classes)\n","\n","        self.full_scale1 = nn.Conv2d(64, 64, kernel_size=1)\n","        self.full_scale2 = nn.Conv2d(128, 64, kernel_size=1)\n","        self.full_scale3 = nn.Conv2d(256, 64, kernel_size=1)\n","        self.full_scale4 = nn.Conv2d(512, 64, kernel_size=1)\n","        self.full_scale5 = nn.Conv2d(512, 64, kernel_size=1)\n","\n","        self.deep_supervision1 = nn.Sequential(\n","            nn.Conv2d(512, n_classes, kernel_size=1),\n","            nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False) \n","        )\n","        self.deep_supervision2 = nn.Sequential(\n","            nn.Conv2d(256, n_classes, kernel_size=1),\n","            nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)  \n","        )\n","        self.deep_supervision3 = nn.Sequential(\n","            nn.Conv2d(128, n_classes, kernel_size=1),\n","            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False) \n","        )\n","        self.deep_supervision4 = nn.Sequential(\n","            nn.Conv2d(64, n_classes, kernel_size=1),\n","            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False) \n","        )\n","        self.deep_supervision5 = nn.Sequential(\n","            nn.Conv2d(64, n_classes, kernel_size=1)\n","        )\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","\n","        fs1 = self.full_scale1(x1)\n","        fs2 = self.full_scale2(x2)\n","        fs3 = self.full_scale3(x3)\n","        fs4 = self.full_scale4(x4)\n","        fs5 = self.full_scale5(x5)\n","\n","        ds1 = self.deep_supervision1(x5)\n","\n","        target_height, target_width = x4.size(2), x4.size(3)\n","        fs1 = F.interpolate(fs1, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs2 = F.interpolate(fs2, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs3 = F.interpolate(fs3, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs4 = F.interpolate(fs4, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        x_up1 = torch.cat([fs1,fs2,fs3,fs4], dim=1)\n","        x = self.up1(x5, x_up1)\n","        ds2 = self.deep_supervision2(x)\n","\n","        target_height, target_width = x3.size(2), x3.size(3)\n","        fs1 = F.interpolate(fs1, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs2 = F.interpolate(fs2, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs3 = F.interpolate(fs3, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs5 = F.interpolate(fs5, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        x_up2 = torch.cat([fs1,fs2,fs3, fs5], dim=1)\n","        x = self.up2(x, x_up2)\n","        ds3 = self.deep_supervision3(x)\n","       \n","        target_height, target_width = x2.size(2), x2.size(3)\n","        fs1 = F.interpolate(fs1, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs2 = F.interpolate(fs2, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs5 = F.interpolate(fs5, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        x_up3 = torch.cat([fs1,fs2,fs5], dim=1)\n","        x = self.up3(x, x_up3)\n","        ds4 = self.deep_supervision4(x)\n","\n","        target_height, target_width = x1.size(2), x1.size(3)\n","        fs1 = F.interpolate(fs1, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        fs5 = F.interpolate(fs5, size=(target_height, target_width), mode='bilinear', align_corners=False)\n","        x_up4 = torch.cat([fs1, fs5], dim=1)\n","        x = self.up4(x, x_up4)\n","        ds5 = self.deep_supervision5(x)\n","\n","        logits = self.outc(x)\n","\n","        return logits, ds1, ds2, ds3, ds4, ds5\n"]},{"cell_type":"markdown","metadata":{"id":"ic4W3V4EbhbU"},"source":["GPU / Определите, можно ли использовать Cuda / To see if Cuda can be used"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1713438240340,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"P_MFMxNzbhbU"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available. GPU support enabled.\n"]}],"source":["if torch.cuda.is_available():\n","    print(\"CUDA is available. GPU is used now.\")\n","    device = torch.device(\"cuda\")\n","else:\n","    print(\"CUDA is not available. Using CPU.\")\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"AwC5qGJRbhbX"},"source":["早停 / Ранняя остановка / Early stopping"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1713438240340,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"lEY2X9ZCbhbX"},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = float('inf')\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss - val_loss > self.min_delta:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True"]},{"cell_type":"markdown","metadata":{"id":"nmC77sxTbhbX"},"source":["训练模型 / обучение модели / model training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1713438240341,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"Lu2GOpo-bhbX"},"outputs":[],"source":["# 初始化模型和优化器 / Инициализация модели и оптимизатора / Initializing the model and optimizer\n","model = UNet3Plus(n_channels=10, n_classes=20)\n","model.load_state_dict(torch.load('best_unet3+_original_1792.pth'))\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=5e-7)\n","scaler = GradScaler()\n","criterion = nn.CrossEntropyLoss()\n","\n","early_stopping = EarlyStopping(patience=5, min_delta=0.0001)\n","\n","# 初始化学习率调度器 / Инициализация планировщика скорости обучения / Initializing the learning rate scheduler\n","scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, verbose=True, min_lr=1e-6)\n","\n","def save_model(model, path):\n","    torch.save(model.state_dict(), path)\n","\n","writer = SummaryWriter()\n","# 记录训练过程 / Запись процесса обучения / Recording the training process\n","train_losses = []\n","val_losses = []\n","overall_accuracies = []\n","precision_scores = []\n","f1_scores = []\n","recall_scores = []\n","best_val_loss = float('inf')  # 初始化最佳验证损失\n","\n","# 训练循环 / Цикл обучения / Training loop\n","epochs = 50 # 训练周期 / Эпохи обучения / Training epochs\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0.0\n","    for batch_idx, batch_data in tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', leave=False):\n","        (inputs, targets) = batch_data\n","        targets = targets.to(device).long()\n","        optimizer.zero_grad()\n","\n","        with autocast():\n","            inputs = torch.squeeze(inputs, dim=1).to(device) \n","            outputs = model(inputs)\n","            logits, ds1, ds2, ds3, ds4, ds5= outputs\n","            loss_main = criterion(logits, targets)\n","            loss_ds1 = criterion(ds1, targets)\n","            loss_ds2 = criterion(ds2, targets)\n","            loss_ds3 = criterion(ds3, targets)\n","            loss_ds4 = criterion(ds4, targets)\n","            loss_ds5 = criterion(ds5, targets)\n","            loss = loss_main + 0.5 * (loss_ds1  + loss_ds2 + loss_ds3 + loss_ds4 + loss_ds5)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        train_loss += loss.item()  # 累加训练损失 / Накопление потерь обучения / Accumulating training loss\n","\n","    train_loss /= len(train_loader)  # 计算平均训练损失 / Вычисление средних потерь обучения / Calculating average training loss\n","\n","    if (epoch +1) % 2 == 0:\n","        # 验证阶段 / Валидация / Validation phase\n","        model.eval()  # 设置模型为评估模式 / Установка модели в режим оценки / Setting the model to evaluation mode\n","        val_loss = 0.0\n","        correct_pixels = 0\n","        total_pixels = 0\n","        all_predictions = []\n","        all_targets = []\n","        with torch.no_grad():  # 在这个阶段不计算梯度 / На этом этапе градиенты не вычисляются / Gradients are not calculated at this stage\n","            for batch_data in valid_loader:\n","                (inputs, targets) = batch_data\n","                targets = targets.to(device).long()\n","                inputs = torch.squeeze(inputs, dim=1).to(device)  # 现在 inputs 的形状是 [batch_size, C, H, W]\n","\n","                outputs = model(inputs)\n","\n","                logits, ds1, ds2, ds3, ds4, ds5= outputs\n","                loss_main = criterion(logits, targets)\n","                loss_ds1 = criterion(ds1, targets)\n","                loss_ds2 = criterion(ds2, targets)\n","                loss_ds3 = criterion(ds3, targets)\n","                loss_ds4 = criterion(ds4, targets)\n","                loss_ds5 = criterion(ds5, targets)\n","                loss = loss_main + 0.5 * (loss_ds1 + loss_ds2+ loss_ds3 + loss_ds4 + loss_ds5)\n","\n","                val_loss += loss.item()  # 累加验证损失 / Накопление потерь валидации / Accumulating validation loss\n","                # 计算准确率 /  Вычисление точности / Calculating accuracy\n","                _, predicted = torch.max(logits, 1)  # 获取最大概率的预测结果 / Получение предсказанных результатов с максимальной вероятностью / Getting predicted results with maximum probability\n","                correct_pixels += (predicted == targets).sum().item()  # 累加正确预测的像素数 / Накопление количества правильно предсказанных пикселей / Accumulating the number of correctly predicted pixels\n","                total_pixels += targets.nelement()  # 累加总像素数 / Накопление общего количества пикселей / Accumulating the total number of pixels\n","                all_predictions.append(predicted.cpu().numpy())\n","                all_targets.append(targets.cpu().numpy())\n","\n","        all_predictions_flattened = np.concatenate(all_predictions).reshape(-1)\n","        all_targets_flattened = np.concatenate(all_targets).reshape(-1)\n","\n","        val_loss /= len(valid_loader)  # 计算平均验证损失 / Вычисление средних потерь валидации / Calculating average validation loss\n","        overall_accuracy = correct_pixels / total_pixels  # 计算总体准确率 / Вычисление общей точности / Calculating overall accuracy\n","        precision = precision_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算精确率 / Вычисление точности / Calculating precision\n","        recall = recall_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算召回率 / Вычисление полноты / Calculating recall\n","        f1 = f1_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算F1 / Вычисление F1 / Calculating F1\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}, Overall Accuracy: {overall_accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n","\n","        train_losses.append(train_loss)  # 记录训练损失 / Запись потерь обучения / Recording training loss\n","        val_losses.append(val_loss)  # 记录验证损失 / Запись потерь валидации / Recording validation loss\n","        overall_accuracies.append(overall_accuracy)  # 记录总体准确率 / Запись общей точности / Recording overall accuracy\n","        precision_scores.append(precision)  # 记录精确率 / Запись точности / Recording precision\n","        recall_scores.append(recall)  # 记录召回率 / Запись полноты / Recording recall\n","        f1_scores.append(f1)  # 记录F1 / Запись F1 / Recording F1\n","\n","        # 记录到TensorBoard / Запись в TensorBoard / Recording to TensorBoard\n","        for name, param in model.named_parameters():\n","            writer.add_histogram(f'Weights/{name}', param, epoch)\n","            if param.grad is not None:\n","                writer.add_histogram(f'Gradients/{name}', param.grad, epoch)\n","        writer.add_scalar('Loss/train', train_loss, epoch)\n","        writer.add_scalar('Loss/val', val_loss, epoch)\n","        writer.add_scalar('Accuracy/overall', overall_accuracy, epoch)\n","        writer.add_scalar('Precision', precision, epoch)\n","        writer.add_scalar('Recall', recall, epoch)\n","        writer.add_scalar('F1', f1, epoch)\n","        writer.add_scalar('Learning rate', optimizer.param_groups[0]['lr'], epoch)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            save_model(model, 'best_unet3+_original.pth')\n","            print(f\"Model saved at Epoch {epoch+1}: Improved validation loss to {best_val_loss:.4f}\")\n","\n","        # 在这里调用学习率调度器，基于验证损失 / Вызов планировщика скорости обучения на основе потерь валидации / Calling the learning rate scheduler here, based on validation loss\n","        scheduler.step(val_loss)\n","\n","        # 检查是否需要早停 / Проверка на необходимость досрочной остановки / Checking if early stopping is needed\n","        early_stopping(val_loss)\n","        if early_stopping.early_stop:\n","            print(\"Early stopping triggered.\")\n","            break\n","writer.close()"]},{"cell_type":"markdown","metadata":{"id":"xIXtv9aubhbY"},"source":["计算mIoU / Рассчитать mIoU / Calculate mIoU"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1713438240341,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"zoJ7VWj9bhbY"},"outputs":[],"source":["def calculate_iou(predicted, target, num_classes):\n","    iou_list = []\n","    for cls in range(num_classes):\n","        pred_inds = predicted == cls\n","        target_inds = target == cls\n","        intersection = (pred_inds & target_inds).sum().item()\n","        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n","        if union == 0:\n","            # 避免除以0 / Избегание деления на 0 / Avoiding division by zero\n","            iou_list.append(float('nan'))  # 该类别未出现在预测和目标中 / Этот класс не появляется в прогнозе и цели / This class does not appear in the prediction and target\n","        else:\n","            iou_list.append(intersection / union)\n","    # 忽略nan值计算平均IoU / Игнорирование значений nan при вычислении среднего IoU / Ignoring nan values when calculating mean IoU\n","    iou_list = [x for x in iou_list if not np.isnan(x)]\n","    mean_iou = sum(iou_list) / len(iou_list) if iou_list else float('nan')\n","    return mean_iou\n","\n","# 模型验证和计算Mean IoU / Проверка модели и вычисление среднего IoU / Model validation and calculating Mean IoU\n","def validate_and_calculate_iou(model, loader, device, num_classes):\n","    model.eval()\n","    total_iou = 0.0\n","    correct_pixels = 0\n","    total_pixels = 0\n","    all_targets = []\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs, targets) in loader:\n","            targets = targets.to(device).long()\n","            inputs = torch.squeeze(inputs, dim=1).to(device) \n","\n","            outputs = model(inputs)\n","            logits, ds1, ds2, ds3, ds4, ds5 = outputs\n","            _, predicted = torch.max(logits, 1)\n","            total_iou += calculate_iou(predicted, targets, num_classes)\n","            # 计算准确率 / Вычисление точности / Calculating accuracy\n","            _, predicted = torch.max(outputs, 1)  # 获取最大概率的预测结果 / Получение предсказанных результатов с максимальной вероятностью / Getting predicted results with maximum probability\n","            correct_pixels += (predicted == targets).sum().item()  # 累加正确预测的像素数 / Накопление количества правильно предсказанных пикселей / Accumulating the number of correctly predicted pixels\n","            total_pixels += targets.nelement()  # 累加总像素数 / Накопление общего количества пикселей / Accumulating the total number of pixels\n","            all_predictions.append(predicted.cpu().numpy())\n","            all_targets.append(targets.cpu().numpy())\n","\n","    # 扁平化预测和目标张量 / Плоскость тензоров предсказаний и целей / Flattening the prediction and target tensors\n","    all_predictions_flattened = np.concatenate(all_predictions).reshape(-1)\n","    all_targets_flattened = np.concatenate(all_targets).reshape(-1)\n","\n","    mean_iou = total_iou / len(loader)\n","    overall_accuracy = correct_pixels / total_pixels  # 计算总体准确率 / Вычисление общей точности / Calculating overall accuracy\n","    precision = precision_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算精确率 / Вычисление точности / Calculating precision\n","    recall = recall_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算召回率 / Вычисление полноты / Calculating recall\n","    f1 = f1_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算Fs1 / Вычисление F1 / Calculating F1\n","    print(f\"Mean IoU on validation set: {mean_iou}, Overall Accuracy: {overall_accuracy:.4f}\", f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"t76-PsuqbhbY"},"source":["验证 / Проверить модель / Validate model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1713438240341,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"MdTMQmPPbhbY"},"outputs":[],"source":["# 调用验证函数 / Вызов функции валидации / Calling the validation function\n","validate_and_calculate_iou(model, valid_loader, device, num_classes)\n","\n","# 计算模型参数数量 / Вычисление количества параметров модели / Calculating the number of model parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total trainable parameters: {total_params}\")\n"]},{"cell_type":"markdown","metadata":{"id":"XOnRYovCbhbY"},"source":["可视化 / Визуализация / Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1713438240341,"user":{"displayName":"Nigel Ning","userId":"05037057044039723428"},"user_tz":-180},"id":"w55lkkcTbhbY"},"outputs":[],"source":["plt.figure(figsize=(12, 5))\n","plt.subplot(1, 3, 1)\n","plt.plot(range(1, len(train_losses)+1), train_losses, label='Train Loss')\n","plt.plot(range(1, len(val_losses)+1), val_losses, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Loss Over Epochs')\n","\n","plt.subplot(1, 3, 2)\n","plt.plot(range(1, len(overall_accuracies)+1), overall_accuracies, label='Overall Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Overall Accuracy')\n","plt.legend()\n","plt.title('Overall Over Epochs')\n","\n","plt.subplot(1, 3, 3)\n","plt.plot(range(1, len(precision_scores)+1), precision_scores, label='Precision')\n","plt.xlabel('Epochs')\n","plt.ylabel('Precision')\n","plt.legend()\n","plt.title('Precision Over Epochs')\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(range(1, len(recall_scores)+1), recall_scores, label='Recall')\n","plt.xlabel('Epochs')\n","plt.ylabel('Recall')\n","plt.legend()\n","plt.title('Recall Over Epochs')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(range(1, len(f1_scores)+1), f1_scores, label='F1')\n","plt.xlabel('Epochs')\n","plt.ylabel('F1')\n","plt.legend()\n","plt.title('F1 Over Epochs')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","conf_mat = confusion_matrix(all_targets_flattened, all_predictions_flattened)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","print(classification_report(all_targets_flattened, all_predictions_flattened))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_data = torch.load('valid_data.pth')\n","\n","class SimpleDataset(torch.utils.data.Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","valid_dataset = SimpleDataset(valid_data)\n","valida_loader = DataLoader(valid_dataset, batch_size=16, collate_fn=pad_collate, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = UNet3Plus(n_channels=10, n_classes=20)\n","model.load_state_dict(torch.load('best_unet3_204.pth'))\n","model.to(device)\n","\n","def visualize_overlay(images, labels, predictions, alpha=0.5, num_images=3):\n","    colors = [\n","    '#FFFFFF',  # white for background class 0\n","    '#E6194B',  # red for class 1\n","    '#3CB44B',  # green for class 2\n","    '#FFE119',  # yellow for class 3\n","    '#4363D8',  # blue for class 4\n","    '#F58231',  # orange for class 5\n","    '#911EB4',  # purple for class 6\n","    '#46F0F0',  # cyan-blue for class 7\n","    '#F032E6',  # pink for class 8\n","    '#BCF60C',  # lime Green for class 9\n","    '#FABEBE',  # light pink for class 10\n","    '#008080',  # light cyan-blue for class 11\n","    '#E6BEFF',  # mauve for class 12\n","    '#9A6324',  # brown for class 13\n","    '#FFFAC8',  # cream for class 14\n","    '#800000',  # maroon for class 15\n","    '#AAFFC3',  # Mint Green for class 16\n","    '#808000',  # Olive Green for class 17\n","    '#FFD8B1',  # coral for class 18\n","    '#000075',  # Dark Blue for class 19\n","    ]\n","\n","    cmap_custom = ListedColormap(colors)\n","    norm = BoundaryNorm(np.arange(len(colors) + 1), cmap_custom.N)  \n","\n","    fig, axs = plt.subplots(num_images, 3, figsize=(15, 5 * num_images))\n","    for i in range(num_images):\n","        if num_images == 1:\n","            ax1, ax2, ax3 = axs\n","        else:\n","            ax1, ax2, ax3 = axs[i]\n","\n","        img_display = images[i][[1, 2, 3]].permute(1, 2, 0).cpu().numpy()\n","        img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min())\n","\n","        ax1.imshow(img_display)\n","        ax1.set_title(\"Original Image - RGB\")\n","        ax1.axis('off')\n","\n","        ax2.imshow(img_display) \n","        ax2.imshow(labels[i].cpu().numpy(), cmap=cmap_custom, norm=norm, alpha=alpha) \n","        ax2.set_title(\"True Label Overlay\")\n","        ax2.axis('off')\n","\n","        ax3.imshow(img_display) \n","        ax3.imshow(predictions[i].cpu().numpy(), cmap=cmap_custom, norm=norm, alpha=alpha) \n","        ax3.set_title(\"Prediction Overlay\")\n","        ax3.axis('off')\n","\n","    plt.show()\n","\n","\n","model.eval()\n","with torch.no_grad():\n","    for (inputs, targets) in valida_loader:\n","        print(inputs.shape)\n","        targets = torch.squeeze(targets, dim=1)\n","        targets = targets.to(device).long()\n","        inputs = torch.squeeze(inputs, dim=1).to(device)  \n","        inputs = torch.squeeze(inputs, dim=1).to(device)\n","\n","        print(inputs.shape, targets.shape)\n","        outputs = model(inputs)\n","        logits, ds1, ds2, ds3 = outputs\n","        _, predicted = torch.max(logits, 1)\n","\n","        visualize_overlay(inputs, targets, predicted, num_images=10)\n","        break  "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
