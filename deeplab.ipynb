{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from dataloader import PASTIS_Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collate import pad_collate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порядок комментариев к коду: китайский / русский / английский."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集加载 / Загрузка набора данных / loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicTimePointDataset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.index_mapping = self._create_index_mapping()\n",
    "\n",
    "    def _create_index_mapping(self):\n",
    "        mapping = []\n",
    "        for idx in self.indices:\n",
    "            (data, dates), target = self.dataset[idx]\n",
    "            s2_data = data['S2']\n",
    "            num_time_points = s2_data.shape[0]\n",
    "            for time_point in range(num_time_points):\n",
    "                mapping.append((idx, time_point))\n",
    "        return mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_mapping)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch_idx, time_point_idx = self.index_mapping[idx]\n",
    "        (data, dates), target = self.dataset[patch_idx]\n",
    "        s2_data = data['S2']\n",
    "        time_point_data = s2_data[time_point_idx].unsqueeze(0)  \n",
    "        return time_point_data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取并处理数据集 / Получение и обработка набора данных / Getting and processing the dataset\n",
    "path_to_dataset = 'E:/Research/Newdata/PASTIS'\n",
    "dataset = PASTIS_Dataset(path_to_dataset, norm=True, target='semantic') # 使用语义分割标签 / Использование меток семантической сегментации / Using semantic segmentation labels\n",
    "\n",
    "subset_indices = torch.randperm(len(dataset))[:1500].tolist()\n",
    "dynamic_dataset = DynamicTimePointDataset(dataset, subset_indices)\n",
    "total_samples = len(dynamic_dataset)\n",
    "print(f\"Total number of data samples: {total_samples}\")\n",
    "\n",
    "# 划分训练集和验证集 / Разделение на обучающий и проверочный наборы / Splitting into training and validation sets\n",
    "train_size = int(0.8 * len(dynamic_dataset))\n",
    "valid_size = len(dynamic_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dynamic_dataset, [train_size, valid_size])\n",
    "\n",
    "# 创建 DataLoader / Создание DataLoader / Creating DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=pad_collate, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, collate_fn=pad_collate, pin_memory=True)\n",
    "\n",
    "# 类别数 / Количество классов / Number of classes\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU / Определите, можно ли использовать Cuda / To see if Cuda can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU is used now.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "早停 / Ранняя остановка / Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "减少deeplab输入通道数 / Уменьшение количества входных каналов deeplab / Reducing the number of input channels for deeplab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_channels(model, in_channels=10):\n",
    "  deeplab_first_conv = model.backbone.conv1\n",
    "  new_first_conv = nn.Conv2d(in_channels, deeplab_first_conv.out_channels, kernel_size=deeplab_first_conv.kernel_size, stride=deeplab_first_conv.stride, padding=deeplab_first_conv.padding, bias=False)\n",
    "  model.backbone.conv1 = new_first_conv\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练  / обучение модели / model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 DeepLab 模型和优化器 / Инициализация модели DeepLab и оптимизатора / Initializing the DeepLab model and optimizer\n",
    "deeplab_model = deeplabv3_resnet50(pretrained=False, num_classes=num_classes).to(device)\n",
    "deeplab_model = reduce_channels(deeplab_model, in_channels=10)\n",
    "model = deeplab_model.to(device)\n",
    "model.load_state_dict(torch.load('best_deepl_0631.pth'))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, verbose=True, min_lr=1e-6)\n",
    "\n",
    "scaler = GradScaler()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "# 记录训练过程 / Запись процесса обучения / Recording the training process\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "overall_accuracies = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "best_val_loss = float('inf')  \n",
    "\n",
    "# 训练循环 / Цикл обучения / Training loop\n",
    "epochs = 50 # 训练周期 / Эпохи обучения / Training epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, batch_data in tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', leave=False):\n",
    "        (inputs, targets) = batch_data\n",
    "        targets = targets.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            inputs = torch.squeeze(inputs, dim=1).to(device) \n",
    "            outputs = model(inputs)['out']\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()  # 累加训练损失 / Накопление потерь обучения / Accumulating training loss\n",
    "\n",
    "    train_loss /= len(train_loader)  # 计算平均训练损失 / Вычисление средних потерь обучения / Calculating average training loss\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        # 验证阶段 / Валидация / Validation phase\n",
    "        model.eval()  # 设置模型为评估模式 / Установка модели в режим оценки / Setting the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct_pixels = 0\n",
    "        total_pixels = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():  # 在这个阶段不计算梯度 / На этом этапе градиенты не вычисляются / Gradients are not calculated at this stage\n",
    "            for batch_data in valid_loader:\n",
    "                (inputs, targets) = batch_data\n",
    "                targets = targets.to(device).long()\n",
    "                inputs = torch.squeeze(inputs, dim=1).to(device)  # 现在 inputs 的形状是 [batch_size, C, H, W]\n",
    "\n",
    "                outputs = model(inputs)['out']\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()  # 累加验证损失 / Накопление потерь валидации / Accumulating validation loss\n",
    "                # 计算准确率 /  Вычисление точности / Calculating accuracy\n",
    "                _, predicted = torch.max(outputs, 1)  # 获取最大概率的预测结果 / Получение предсказанных результатов с максимальной вероятностью / Getting predicted results with maximum probability\n",
    "                correct_pixels += (predicted == targets).sum().item()  # 累加正确预测的像素数 / Накопление количества правильно предсказанных пикселей / Accumulating the number of correctly predicted pixels\n",
    "                total_pixels += targets.nelement()  # 累加总像素数 / Накопление общего количества пикселей / Accumulating the total number of pixels\n",
    "                all_predictions.append(predicted.cpu().numpy())\n",
    "                all_targets.append(targets.cpu().numpy()) \n",
    "\n",
    "        all_predictions_flattened = np.concatenate(all_predictions).reshape(-1)\n",
    "        all_targets_flattened = np.concatenate(all_targets).reshape(-1)\n",
    "\n",
    "        val_loss /= len(valid_loader)  # 计算平均验证损失 / Вычисление средних потерь валидации / Calculating average validation loss\n",
    "        overall_accuracy = correct_pixels / total_pixels  # 计算总体准确率 / Вычисление общей точности / Calculating overall accuracy\n",
    "        precision = precision_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算精确率 / Вычисление точности / Calculating precision\n",
    "        recall = recall_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算召回率 / Вычисление полноты / Calculating recall\n",
    "        f1 = f1_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算F1 / Вычисление F1 / Calculating F1\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}, Overall Accuracy: {overall_accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)  # 记录训练损失 / Запись потерь обучения / Recording training loss\n",
    "        val_losses.append(val_loss)  # 记录验证损失 / Запись потерь валидации / Recording validation loss\n",
    "        overall_accuracies.append(overall_accuracy)  # 记录总体准确率 / Запись общей точности / Recording overall accuracy\n",
    "        precision_scores.append(precision)  # 记录精确率 / Запись точности / Recording precision\n",
    "        recall_scores.append(recall)  # 记录召回率 / Запись полноты / Recording recall\n",
    "        f1_scores.append(f1)  # 记录F1 / Запись F1 / Recording F1\n",
    "\n",
    "        # 记录到TensorBoard / Запись в TensorBoard / Recording to TensorBoard\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f'Weights/{name}', param, epoch)\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'Gradients/{name}', param.grad, epoch)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/overall', overall_accuracy, epoch)\n",
    "        writer.add_scalar('Precision', precision, epoch)\n",
    "        writer.add_scalar('Recall', recall, epoch)\n",
    "        writer.add_scalar('F1', f1, epoch)\n",
    "        writer.add_scalar('Learning rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, 'best_model_state_dict.pth')\n",
    "            print(f\"Model saved at Epoch {epoch+1}: Improved validation loss to {best_val_loss:.4f}\")\n",
    "\n",
    "        # 在这里调用学习率调度器，基于验证损失 / Вызов планировщика скорости обучения на основе потерь валидации / Calling the learning rate scheduler here, based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # 检查是否需要早停 / Проверка на необходимость досрочной остановки / Checking if early stopping is needed\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算mIoU / Рассчитать mIoU / Calculate mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(predicted, target, num_classes):\n",
    "    iou_list = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = predicted == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
    "        if union == 0:\n",
    "            # 避免除以0 / Избегание деления на 0 / Avoiding division by zero\n",
    "            iou_list.append(float('nan'))  # 该类别未出现在预测和目标中 / Этот класс не появляется в прогнозе и цели / This class does not appear in the prediction and target\n",
    "        else:\n",
    "            iou_list.append(intersection / union)\n",
    "    # 忽略nan值计算平均IoU / Игнорирование значений nan при вычислении среднего IoU / Ignoring nan values when calculating mean IoU\n",
    "    iou_list = [x for x in iou_list if not np.isnan(x)]\n",
    "    mean_iou = sum(iou_list) / len(iou_list) if iou_list else float('nan')\n",
    "    return mean_iou\n",
    "\n",
    "# 模型验证和计算Mean IoU / Проверка модели и вычисление среднего IoU / Model validation and calculating Mean IoU\n",
    "def validate_and_calculate_iou(model, loader, device, num_classes):\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs, targets) in loader:\n",
    "            targets = targets.to(device).long()\n",
    "            inputs = torch.squeeze(inputs, dim=1).to(device)  # 现在 inputs 的形状是 [batch_size, C, H, W]\n",
    "\n",
    "            outputs = model(inputs)['out']\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_iou += calculate_iou(predicted, targets, num_classes)\n",
    "            # 计算准确率 / Вычисление точности / Calculating accuracy\n",
    "            _, predicted = torch.max(outputs, 1)  # 获取最大概率的预测结果 / Получение предсказанных результатов с максимальной вероятностью / Getting predicted results with maximum probability\n",
    "            correct_pixels += (predicted == targets).sum().item()  # 累加正确预测的像素数 / Накопление количества правильно предсказанных пикселей / Accumulating the number of correctly predicted pixels\n",
    "            total_pixels += targets.nelement()  # 累加总像素数 / Накопление общего количества пикселей / Accumulating the total number of pixels\n",
    "            all_predictions.append(predicted.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # 扁平化预测和目标张量 / Плоскость тензоров предсказаний и целей / Flattening the prediction and target tensors\n",
    "    all_predictions_flattened = np.concatenate(all_predictions).reshape(-1)\n",
    "    all_targets_flattened = np.concatenate(all_targets).reshape(-1)\n",
    "\n",
    "    mean_iou = total_iou / len(loader)\n",
    "    overall_accuracy = correct_pixels / total_pixels  # 计算总体准确率 / Вычисление общей точности / Calculating overall accuracy\n",
    "    precision = precision_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算精确率 / Вычисление точности / Calculating precision\n",
    "    recall = recall_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算召回率 / Вычисление полноты / Calculating recall\n",
    "    f1 = f1_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算Fs1 / Вычисление F1 / Calculating F1\n",
    "    print(f\"Mean IoU on validation set: {mean_iou}, Overall Accuracy: {overall_accuracy:.4f}\", f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 / Проверить модель / Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用验证函数 / Вызов функции валидации / Calling the validation function\n",
    "validate_and_calculate_iou(model, valid_loader, device, num_classes)\n",
    "\n",
    "# 计算模型参数数量 / Вычисление количества параметров модели / Calculating the number of model parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化 / Визуализация / Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, len(val_losses)+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, len(overall_accuracies)+1), overall_accuracies, label='Overall Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Overall Over Epochs')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, len(precision_scores)+1), precision_scores, label='Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.title('Precision Over Epochs')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(range(1, len(recall_scores)+1), recall_scores, label='Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.title('Recall Over Epochs')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(range(1, len(f1_scores)+1), f1_scores, label='F1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()\n",
    "plt.title('F1 Over Epochs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "conf_mat = confusion_matrix(all_targets_flattened, all_predictions_flattened)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(all_targets_flattened, all_predictions_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = torch.load('valid_data.pth')\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "valid_dataset = SimpleDataset(valid_data)\n",
    "valida_loader = DataLoader(valid_dataset, batch_size=16, collate_fn=pad_collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_model = deeplabv3_resnet50(pretrained=False, num_classes=20).to(device)\n",
    "deeplab_model = reduce_channels(deeplab_model, in_channels=10)\n",
    "model = deeplab_model.to(device)\n",
    "model.load_state_dict(torch.load('best_deepl_0631.pth'))\n",
    "model.to(device)\n",
    "\n",
    "def visualize_overlay(images, labels, predictions, alpha=0.5, num_images=3):\n",
    "    colors = [\n",
    "    '#FFFFFF',  # white for background class 0\n",
    "    '#E6194B',  # red for class 1\n",
    "    '#3CB44B',  # green for class 2\n",
    "    '#FFE119',  # yellow for class 3\n",
    "    '#4363D8',  # blue for class 4\n",
    "    '#F58231',  # orange for class 5\n",
    "    '#911EB4',  # purple for class 6\n",
    "    '#46F0F0',  # cyan-blue for class 7\n",
    "    '#F032E6',  # pink for class 8\n",
    "    '#BCF60C',  # lime Green for class 9\n",
    "    '#FABEBE',  # light pink for class 10\n",
    "    '#008080',  # light cyan-blue for class 11\n",
    "    '#E6BEFF',  # mauve for class 12\n",
    "    '#9A6324',  # brown for class 13\n",
    "    '#FFFAC8',  # cream for class 14\n",
    "    '#800000',  # maroon for class 15\n",
    "    '#AAFFC3',  # Mint Green for class 16\n",
    "    '#808000',  # Olive Green for class 17\n",
    "    '#FFD8B1',  # coral for class 18\n",
    "    '#000075',  # Dark Blue for class 19\n",
    "    ]\n",
    "\n",
    "    cmap_custom = ListedColormap(colors)\n",
    "    norm = BoundaryNorm(np.arange(len(colors) + 1), cmap_custom.N) \n",
    "\n",
    "    fig, axs = plt.subplots(num_images, 3, figsize=(15, 5 * num_images))\n",
    "    for i in range(num_images):\n",
    "        if num_images == 1:\n",
    "            ax1, ax2, ax3 = axs\n",
    "        else:\n",
    "            ax1, ax2, ax3 = axs[i]\n",
    "\n",
    "        img_display = images[i][[1, 2, 3]].permute(1, 2, 0).cpu().numpy()\n",
    "        img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min())\n",
    "\n",
    "        ax1.imshow(img_display)\n",
    "        ax1.set_title(\"Original Image - RGB\")\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.imshow(img_display)\n",
    "        ax2.imshow(labels[i].cpu().numpy(), cmap=cmap_custom, norm=norm, alpha=alpha) \n",
    "        ax2.set_title(\"True Label Overlay\")\n",
    "        ax2.axis('off')\n",
    "\n",
    "        ax3.imshow(img_display) \n",
    "        ax3.imshow(predictions[i].cpu().numpy(), cmap=cmap_custom, norm=norm, alpha=alpha) \n",
    "        ax3.set_title(\"Prediction Overlay\")\n",
    "        ax3.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (inputs, targets) in valida_loader:\n",
    "        print(inputs.shape)\n",
    "        targets = torch.squeeze(targets, dim=1)\n",
    "        targets = targets.to(device).long()\n",
    "        inputs = torch.squeeze(inputs, dim=1).to(device) \n",
    "        inputs = torch.squeeze(inputs, dim=1).to(device)\n",
    "\n",
    "        print(inputs.shape, targets.shape)\n",
    "        outputs = model(inputs)['out']\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        visualize_overlay(inputs, targets, predicted, num_images=10)\n",
    "        break  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
