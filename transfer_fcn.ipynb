{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "from tqdm.auto import tqdm\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision.transforms import ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像预处理 / Предварительная обработка изображений / Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransform:\n",
    "    def __call__(self, x):\n",
    "        if random.random() > 0.5:\n",
    "            x = torch.flip(x, [2])\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            x = torch.flip(x, [1])\n",
    "        \n",
    "        k = random.choice([0, 1, 2, 3])\n",
    "        x = torch.rot90(x, k, [1, 2])\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            brightness_factor = random.uniform(0.9, 1.1)\n",
    "            x = x * brightness_factor\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            noise = torch.randn_like(x) * 0.02  \n",
    "            x = x + noise\n",
    "        \n",
    "        return x\n",
    "transform = CustomTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像分割 / Сегментация изображений / Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images_and_labels(image_paths, label_paths, tile_size=(128, 128), overlap=0.1, ignore_label=0):\n",
    "    stride = int(tile_size[0] * (1 - overlap))  \n",
    "    image_tiles = []\n",
    "    label_tiles = []\n",
    "\n",
    "    for image_path, label_path in zip(image_paths, label_paths):\n",
    "        with rasterio.open(image_path) as img:\n",
    "            with rasterio.open(label_path) as lbl:\n",
    "                for top in range(0, lbl.height - tile_size[1] + 1, stride):\n",
    "                    for left in range(0, lbl.width - tile_size[0] + 1, stride):\n",
    "                        window = Window(left, top, tile_size[0], tile_size[1])\n",
    "                        img_tile = img.read(window=window)\n",
    "                        lbl_tile = lbl.read(1, window=window)\n",
    "\n",
    "                        if np.any(lbl_tile != ignore_label):\n",
    "                            image_tiles.append(img_tile)\n",
    "                            label_tiles.append(lbl_tile)\n",
    "\n",
    "    return image_tiles, label_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_tiles, label_tiles, transform=None):\n",
    "        self.image_tiles = image_tiles\n",
    "        self.label_tiles = label_tiles\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_tiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.image_tiles) or idx >= len(self.label_tiles):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        image = self.image_tiles[idx].astype(np.float32)  \n",
    "        image = torch.from_numpy(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if image.dim() == 4:  \n",
    "            image = image.permute(0, 2, 1, 3)  \n",
    "\n",
    "        label = self.label_tiles[idx].astype(np.int64)\n",
    "        label = torch.from_numpy(label) \n",
    "\n",
    "        if label.ndim > 2:\n",
    "            label = label.squeeze(0)  \n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集加载 / Загрузка набора данных / loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    r'E:\\Research\\code\\newdata\\1.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\2.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\3.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\4.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\5.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\6.tiff',\n",
    "]\n",
    "\n",
    "label_paths = [\n",
    "    r'E:\\Research\\code\\newdata\\1_mask.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\2_mask.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\3_mask.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\4_mask.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\5_mask.tiff',\n",
    "    r'E:\\Research\\code\\newdata\\6_mask.tiff',\n",
    "]\n",
    "\n",
    "image_tiles, label_tiles = split_images_and_labels(image_paths, label_paths)\n",
    "\n",
    "print(\"Loaded image tiles:\", len(image_tiles))\n",
    "print(\"Loaded label tiles:\", len(label_tiles))\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "full_dataset = CustomDataset(image_tiles, label_tiles, transform=transform)\n",
    "\n",
    "dataset_size = len(full_dataset) \n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_size = int(0.8 * dataset_size) \n",
    "train_indices = indices[:train_size] \n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "class_counts = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "for labels in label_tiles:\n",
    "    labels = labels.flatten() \n",
    "    labels = labels.astype(np.int64)\n",
    "    counts = np.bincount(labels, minlength=num_classes)\n",
    "    class_counts += counts\n",
    "\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights[np.isinf(class_weights)] = 0  \n",
    "\n",
    "sample_weights = []\n",
    "for labels in label_tiles:\n",
    "    labels = labels.flatten()\n",
    "    labels = labels.astype(np.int64) \n",
    "    weights = class_weights[labels]\n",
    "    sample_weights.append(weights)\n",
    "\n",
    "sample_weights = np.concatenate(sample_weights)\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_sample_weights = [sample_weights[i] for i in train_indices]\n",
    "\n",
    "train_sampler = WeightedRandomSampler(train_sample_weights, len(train_sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(Subset(full_dataset, train_indices), batch_size=16, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(Subset(full_dataset, val_indices), batch_size=16, shuffle=True)\n",
    "\n",
    "valid_data = [(data, label) for data, label in DataLoader(Subset(full_dataset, val_indices), batch_size=1)]\n",
    "torch.save(valid_data, 'new_valid_data.pth')\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)  \n",
    "\n",
    "print(\"Label max:\", labels.max())\n",
    "print(\"Label min:\", labels.min())\n",
    "\n",
    "def print_batch_class_distribution(loader, num_classes):\n",
    "    for images, labels in loader:\n",
    "        labels_flattened = labels.view(-1).numpy()\n",
    "        class_counts = Counter(labels_flattened)\n",
    "        distribution = {k: class_counts.get(k, 0) for k in range(num_classes)}\n",
    "        print(f\"Batch class distribution: {distribution}\")\n",
    "\n",
    "print_batch_class_distribution(train_loader, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN10Channel(nn.Module):\n",
    "    def __init__(self, num_channels=4, num_classes=7):\n",
    "        super(FCN10Channel, self).__init__()\n",
    "        vgg = models.vgg16(pretrained=True)\n",
    "        features = list(vgg.features.children())\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.7)\n",
    "\n",
    "        features[0] = nn.Conv2d(4, 64, kernel_size=3, padding=1)\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        for layer in self.features[:-6]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        self.upsample = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, stride=32, padding=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) \n",
    "        x = self.fcn(x)     \n",
    "        x = self.upsample(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "早停 / Ранняя остановка / Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU / Определите, можно ли использовать Cuda / To see if Cuda can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU is used now.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练  / обучение модели / model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN10Channel(num_channels=4, num_classes=7).to(device)\n",
    "\n",
    "pretrained_dict = torch.load('best_fcn.pth')\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].size() == v.size()}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "model.to(device)\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.0001)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6, weight_decay=1e-6)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "scaler = GradScaler()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.1, verbose=True, min_lr=1e-6)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "overall_accuracies = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "best_val_loss = float('inf') \n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', leave=True):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    if (epoch +1) % 2 == 0:\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        correct_pixels = 0\n",
    "        total_pixels = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_pixels += (predicted == labels).sum().item()  # 累加正确预测的像素数 / Накопление количества правильно предсказанных пикселей / Accumulating the number of correctly predicted pixels\n",
    "                total_pixels += labels.nelement()  # 累加总像素数 / Накопление общего количества пикселей / Accumulating the total number of pixels\n",
    "                all_predictions.append(predicted.cpu().numpy())\n",
    "                all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "        # 使用np.concatenate来合并列表中的所有数组，然后进行扁平化处理\n",
    "        all_predictions_flattened = np.concatenate(all_predictions).reshape(-1)\n",
    "        all_targets_flattened = np.concatenate(all_targets).reshape(-1)\n",
    "\n",
    "        val_loss /= len(val_loader)  # 计算平均验证损失 / Вычисление средних потерь валидации / Calculating average validation loss\n",
    "        overall_accuracy = correct_pixels / total_pixels  # 计算总体准确率 / Вычисление общей точности / Calculating overall accuracy\n",
    "        precision = precision_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算精确率 / Вычисление точности / Calculating precision\n",
    "        recall = recall_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算召回率 / Вычисление полноты / Calculating recall\n",
    "        f1 = f1_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算F1 / Вычисление F1 / Calculating F1\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}, Overall Accuracy: {overall_accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)  \n",
    "        val_losses.append(val_loss)  \n",
    "        overall_accuracies.append(overall_accuracy) \n",
    "        precision_scores.append(precision)  \n",
    "        recall_scores.append(recall)  \n",
    "        f1_scores.append(f1)  \n",
    "\n",
    "        # 记录到TensorBoard / Запись в TensorBoard / Recording to TensorBoard\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f'Weights/{name}', param, epoch)\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'Gradients/{name}', param.grad, epoch)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/overall', overall_accuracy, epoch)\n",
    "        writer.add_scalar('Precision', precision, epoch)\n",
    "        writer.add_scalar('Recall', recall, epoch)\n",
    "        writer.add_scalar('F1', f1, epoch)\n",
    "        writer.add_scalar('Learning rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, 'best_new_fcn_state_dict.pth')\n",
    "            print(f\"Model saved at Epoch {epoch+1}: Improved validation loss to {best_val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)  # 更新学习率 / Обновление скорости обучения / Updating the learning rate\n",
    "        early_stopping(val_loss)  # 检查是否需要提前停止 / Проверка на необходимость досрочного завершения / Checking if early stopping criterion is met\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算mIoU / Рассчитать mIoU / Calculate mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(predicted, target, num_classes):\n",
    "    iou_list = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = predicted == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
    "        if union == 0:\n",
    "            # 避免除以0 / Избегание деления на 0 / Avoiding division by zero\n",
    "            iou_list.append(float('nan'))  # 该类别未出现在预测和目标中 / Этот класс не появляется в прогнозе и цели / This class does not appear in the prediction and target\n",
    "        else:\n",
    "            iou_list.append(intersection / union)\n",
    "    # 忽略nan值计算平均IoU / Игнорирование значений nan при вычислении среднего IoU / Ignoring nan values when calculating mean IoU\n",
    "    iou_list = [x for x in iou_list if not np.isnan(x)]\n",
    "    mean_iou = sum(iou_list) / len(iou_list) if iou_list else float('nan')\n",
    "    return mean_iou\n",
    "\n",
    "# 模型验证和计算Mean IoU / Проверка модели и вычисление среднего IoU / Model validation and calculating Mean IoU\n",
    "def validate_and_calculate_iou(model, loader, device, num_classes):\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_iou += calculate_iou(predicted, labels, num_classes)\n",
    "            # 计算准确率 / Вычисление точности / Calculating accuracy\n",
    "            correct_pixels += (predicted == labels).sum().item()  # 累加正确预测的像素数 / Накопление количества правильно предсказанных пикселей / Accumulating the number of correctly predicted pixels\n",
    "            total_pixels += labels.nelement()  # 累加总像素数 / Накопление общего количества пикселей / Accumulating the total number of pixels\n",
    "            all_predictions.append(predicted.cpu().numpy())\n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "    # 扁平化预测和目标张量 / Плоскость тензоров предсказаний и целей / Flattening the prediction and target tensors\n",
    "    all_predictions_flattened = np.concatenate(all_predictions).reshape(-1)\n",
    "    all_targets_flattened = np.concatenate(all_targets).reshape(-1)\n",
    "\n",
    "    mean_iou = total_iou / len(loader)\n",
    "    overall_accuracy = correct_pixels / total_pixels  # 计算总体准确率 / Вычисление общей точности / Calculating overall accuracy\n",
    "    precision = precision_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算精确率 / Вычисление точности / Calculating precision\n",
    "    recall = recall_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算召回率 / Вычисление полноты / Calculating recall\n",
    "    f1 = f1_score(all_targets_flattened, all_predictions_flattened, average='macro', zero_division=0)  # 计算Fs1 / Вычисление F1 / Calculating F1\n",
    "    print(f\"Mean IoU on validation set: {mean_iou}, Overall Accuracy: {overall_accuracy:.4f}\", f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 / Проверить модель / Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "# 调用验证函数 / Вызов функции валидации / Calling the validation function\n",
    "validate_and_calculate_iou(model, val_loader, device, num_classes)\n",
    "\n",
    "# 计算模型参数数量 / Вычисление количества параметров модели / Calculating the number of model parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
